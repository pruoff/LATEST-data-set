{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data and Transform for Publication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the notebook used to import the raw data from influxDB and transform it to a publishable format as csv file\n",
    "\n",
    "Version = 1.0\n",
    "\n",
    "Author = Patrick Ruoff\n",
    "\n",
    "The environment is in conda_env.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from influxdb import DataFrameClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_df_from_influxdb():\n",
    "    \"\"\" Read data from influxDB instance\n",
    "\n",
    "    Filter for specified time frame. Remove data in occGaps as specified in setup.py.\n",
    "    Bring all datapoint to 30s frequency and handle duplicates. Drop a user's data\n",
    "    if certain important features are missing for the full time frame.\n",
    "\n",
    "    :return: DataFrame with all the data\n",
    "    \"\"\"\n",
    "\n",
    "    host = 'localhost'\n",
    "    port = 8086\n",
    "    user = 'pythonServer'\n",
    "    reader = open('influxdb_password.txt')\n",
    "    password = reader.read()\n",
    "    dbname = 'openhab_db'\n",
    "    client = DataFrameClient(host, port, user, password, dbname)\n",
    "\n",
    "    global isMessagePrinted\n",
    "    for gapInfo in se.occGaps:\n",
    "        isMessagePrinted[gapInfo[0]] = False\n",
    "\n",
    "    print('Starting import from {} between {} and {}'.format(\n",
    "        dbname, se.startTime, se.endTime))\n",
    "    # NOTE: beware that timestamps now are +00:00 -> different from Grafana\n",
    "    data = pd.DataFrame()\n",
    "\n",
    "    if not np.shape(se.inputSeries) == np.shape(se.outputSeries):\n",
    "        print('InputSerieses and se.outputSerieses must have the same number of entries! '\n",
    "              'Found: {}, {}'\n",
    "              .format(np.shape(se.inputSeries), np.shape(se.outputSeries)))\n",
    "\n",
    "    start_time_unix = \"{}000000000\".format(int(pd.to_datetime(se.startTime).timestamp()))\n",
    "    end_time_unix = \"{}000000000\".format(int(pd.to_datetime(se.endTime).timestamp()))\n",
    "    # first is different from others\n",
    "    data_frames = {}\n",
    "    i = 0\n",
    "    while i < np.shape(se.inputSeries)[0]:\n",
    "        try:\n",
    "            data_frames[se.outputSeries[i]] = client.query(\n",
    "                \"SELECT * FROM {} WHERE time > {} AND time < {}\".format(\n",
    "                    se.inputSeries[i], start_time_unix, end_time_unix))[se.inputSeries[i]]\n",
    "        except KeyError:\n",
    "            print('Input series {} has no entries in specified time frame'.format(\n",
    "                se.inputSeries[i]))\n",
    "            if se.outputSeries[i] in se.seriesEnvironment:\n",
    "                se.seriesEnvironment.remove(se.outputSeries[i])\n",
    "                if se.outputSeries[i] in se.categoricalSeries:\n",
    "                    se.categoricalSeries.remove(se.outputSeries[i])\n",
    "            elif se.outputSeries[i] in se.seriesBiosignal:\n",
    "                if se.outputSeries[i][:2] in se.availableUsers:\n",
    "                    se.availableUsers.remove(se.outputSeries[i][:2])\n",
    "                se.seriesBiosignal.remove(se.outputSeries[i])\n",
    "            else:\n",
    "                se.seriesVote.remove(se.outputSeries[i])\n",
    "            del se.inputSeries[i]\n",
    "            del se.outputSeries[i]\n",
    "            continue\n",
    "\n",
    "        for gapInfo in se.occGaps:\n",
    "            if gapInfo[0] >= pd.DataFrame(data_frames[se.outputSeries[i]]).index[0] and \\\n",
    "                    gapInfo[1] <= pd.DataFrame(\n",
    "                    data_frames[se.outputSeries[i]]).index[-1]:\n",
    "                pd.DataFrame(data_frames[se.outputSeries[i]]).loc['{}:{}'.format(\n",
    "                    gapInfo[0], gapInfo[1])] = np.nan\n",
    "                if not isMessagePrinted[gapInfo[0]]:\n",
    "                    print('Drop entries between {} and {} as specified in setup.'.format(\n",
    "                        gapInfo[0], gapInfo[1]))\n",
    "                    isMessagePrinted[gapInfo[0]] = True\n",
    "\n",
    "        current_df = pd.DataFrame(data_frames[se.outputSeries[i]])\n",
    "        current_df.columns = [se.outputSeries[i]]\n",
    "        # round to 30 seconds\n",
    "        new_indices = []\n",
    "        for ind in data_frames[se.outputSeries[i]][se.outputSeries[i]].index:\n",
    "            ind = ind.replace(second=floor(ind.second/30)*30, microsecond=0, nanosecond=0)\n",
    "            new_indices.append(ind)\n",
    "        current_df.index = new_indices\n",
    "        data_frames[se.outputSeries[i]] = current_df\n",
    "        i += 1\n",
    "\n",
    "    # check if all series of missing users are removed from seriesesBio, -Vote, and -Env\n",
    "    # without biosignal data, environmental and vote data can be dropped\n",
    "    j = 0\n",
    "    while j < np.shape(se.seriesVote)[0]:\n",
    "        if se.seriesVote[j][0] == 'U':\n",
    "            if not se.seriesVote[j][:2] in se.availableUsers:\n",
    "                print('WARNING: {} has values even though other series'\n",
    "                      ' of the same user are missing!'.format(se.seriesVote[j]))\n",
    "                print('Removing {} since userdata is not available.'.format(\n",
    "                    se.seriesVote[j]))\n",
    "                se.outputSeries.remove(se.seriesVote[j])\n",
    "                del data_frames[se.seriesVote[j]]\n",
    "                se.seriesVote.remove(se.seriesVote[j])\n",
    "                continue\n",
    "        j += 1\n",
    "    j = 0\n",
    "    while j < np.shape(se.seriesBiosignal)[0]:\n",
    "        if se.seriesBiosignal[j][0] == 'U':\n",
    "            if not se.seriesBiosignal[j][:2] in se.availableUsers:\n",
    "                print('WARNING: {} has values even though other series'\n",
    "                      ' of the same user are missing!'.format(se.seriesBiosignal[j]))\n",
    "                print('Removing {} since userdata is not available.'.format(\n",
    "                    se.seriesBiosignal[j]))\n",
    "                se.outputSeries.remove(se.seriesBiosignal[j])\n",
    "                del data_frames[se.seriesBiosignal[j]]\n",
    "                se.seriesBiosignal.remove(se.seriesBiosignal[j])\n",
    "                continue\n",
    "        j += 1\n",
    "    j = 0\n",
    "    while j < np.shape(se.seriesEnvironment)[0]:\n",
    "        if se.seriesEnvironment[j][0] == 'U':\n",
    "            if not se.seriesEnvironment[j][:2] in se.availableUsers:\n",
    "                print('WARNING: {} has values even though other series'\n",
    "                      ' of the same user are missing!'.format(se.seriesEnvironment[j]))\n",
    "                print('Removing {} since userdata is not available.'.format(\n",
    "                    se.seriesEnvironment[j]))\n",
    "                se.outputSeries.remove(se.seriesEnvironment[j])\n",
    "                del data_frames[se.seriesEnvironment[j]]\n",
    "                se.seriesEnvironment.remove(se.seriesEnvironment[j])\n",
    "                continue\n",
    "        j += 1\n",
    "\n",
    "    # update userSerieses\n",
    "    for user in se.availableUsers:\n",
    "        se.userSeries[user] = []\n",
    "        for series in se.outputSeries:\n",
    "            if user in series:\n",
    "                se.userSeries[user].append(series)\n",
    "\n",
    "    # unite to one df\n",
    "    data = pd.DataFrame([], index=pd.date_range(\n",
    "        start=se.startTime, end=se.endTime, freq='30s'))\n",
    "    for i in (np.arange(np.shape(se.outputSeries)[0])):\n",
    "        print('i', i, data_frames[se.outputSeries[i]].columns)\n",
    "        # handle duplicates\n",
    "        is_duplicated_array = data_frames[se.outputSeries[i]].index.duplicated(False)\n",
    "        if any(is_duplicated_array):\n",
    "            data_frames[se.outputSeries[i]].index.name = 'index'\n",
    "            print('duplicated indices:\\n',\n",
    "                  data_frames[se.outputSeries[i]][is_duplicated_array])\n",
    "            duplicated_indices = np.unique(\n",
    "                (data_frames[se.outputSeries[i]][is_duplicated_array]).index.to_numpy())\n",
    "            if data_frames[se.outputSeries[i]]._get_numeric_data().columns.empty:\n",
    "                # for categorical data\n",
    "                data_frames[se.outputSeries[i]] = \\\n",
    "                    data_frames[se.outputSeries[i]].groupby('index').last()\n",
    "            else:\n",
    "                if se.outputSeries[i] in se.seriesEnvironment or \\\n",
    "                        se.outputSeries[i] in se.seriesBiosignal:\n",
    "                    # for numerical sensor data\n",
    "                    data_frames[se.outputSeries[i]] = \\\n",
    "                        data_frames[se.outputSeries[i]].groupby('index').mean()\n",
    "                else:\n",
    "                    # for numerical voting data use last voting\n",
    "                    data_frames[se.outputSeries[i]] = \\\n",
    "                        data_frames[se.outputSeries[i]].groupby('index').last()\n",
    "            print('\\nare merged to:\\n',\n",
    "                  data_frames[se.outputSeries[i]].loc[duplicated_indices])\n",
    "        # used to be data[se.outputSerieses[i]] = data_frames[se.outputSerieses[i]]\n",
    "        # but that limits the time span to the first series' last value\n",
    "        data = data.merge(\n",
    "            right=data_frames[se.outputSeries[i]], how='outer',\n",
    "            left_index=True, right_index=True)\n",
    "\n",
    "    # make categorical features strings\n",
    "    for i, series in enumerate(se.categoricalSeries):\n",
    "        if series in data.columns:\n",
    "            data[series] = data[series].astype(str)\n",
    "            # nan values stay np.nan\n",
    "            data[series] = data[series].replace('nan', np.nan)\n",
    "        else:\n",
    "            del se.categoricalSeries[i]\n",
    "    data.index.name = 'index'\n",
    "\n",
    "    print('Data from {} to {} in influxDB is of size {}'.format(se.startTime, se.endTime, np.shape(data)))\n",
    "    return data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
